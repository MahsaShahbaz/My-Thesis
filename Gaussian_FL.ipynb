{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95fb4005-4b75-458b-b309-720aa1b58e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mahsa/Desktop/FL/src\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('Desktop/src')\n",
    "\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf906fe9-8ce5-4e56-9f5c-11c21fea64ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 13:39:59,213 - INFO - Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2024-06-11 13:39:59,213 - INFO - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "from options import args_parser\n",
    "from update_s3_gradient_matching import LocalUpdate\n",
    "from utils import test_inference\n",
    "from models import CNNMnistRelu, CNNMnistTanh\n",
    "from models import CNNFashion_MnistRelu, CNNFashion_MnistTanh\n",
    "from models import CNNCifar10Relu, CNNCifar10Tanh\n",
    "from utils import average_weights, exp_details\n",
    "from datasets import get_dataset\n",
    "from torchvision import models\n",
    "from logging_results import logging\n",
    "from opacus.dp_model_inspector import DPModelInspector\n",
    "from opacus.utils import module_modification\n",
    "from opacus import PrivacyEngine\n",
    "\n",
    "from seed_manager import set_seed\n",
    "set_seed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb06160-c047-48c4-87df-9ef4f06211ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0.5, Noise Multiplier: 8.69\n",
      "Epsilon: 1.0, Noise Multiplier: 4.34\n",
      "Epsilon: 1.5, Noise Multiplier: 2.90\n",
      "Epsilon: 2.0, Noise Multiplier: 2.17\n",
      "Epsilon: 2.5, Noise Multiplier: 1.74\n",
      "Epsilon: 3.0, Noise Multiplier: 1.45\n",
      "Epsilon: 10.0, Noise Multiplier: 0.43\n"
     ]
    }
   ],
   "source": [
    "def calculate_noise_multiplier(epsilon, delta=1e-4, sensitivity=1.0):\n",
    "    \"\"\"\n",
    "    Calculate the noise multiplier for Gaussian mechanism based on epsilon, delta, and sensitivity.\n",
    "\n",
    "    Parameters:\n",
    "        epsilon (float): Privacy budget epsilon.\n",
    "        delta (float): Privacy parameter delta. Default is 1e-4.\n",
    "        sensitivity (float): Sensitivity of the function. Default is 1.0.\n",
    "\n",
    "    Returns:\n",
    "        float: Noise multiplier for Gaussian mechanism.\n",
    "    \"\"\"\n",
    "    return np.sqrt(2 * np.log(1.25 / delta)) / epsilon\n",
    "\n",
    "# Define epsilon values for which to calculate the noise multiplier\n",
    "epsilon_values = [0.50, 1.0, 1.50, 2.0, 2.50, 3.0, 10.0]\n",
    "\n",
    "# Calculate and print the noise multipliers for the given epsilon values\n",
    "noise_multipliers = {epsilon: calculate_noise_multiplier(epsilon) for epsilon in epsilon_values}\n",
    "\n",
    "for epsilon, noise_multiplier in noise_multipliers.items():\n",
    "    print(f\"Epsilon: {epsilon}, Noise Multiplier: {noise_multiplier:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbb473f1-2c5b-46ef-ab2d-052d148a08a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(model, train_loss, test_log, all_output_gradients):\n",
    "    \"\"\"\n",
    "    Saves the training results, including the model state, losses, test metrics, and output gradients,\n",
    "    using torch.save for better compatibility with PyTorch objects.\n",
    "    \n",
    "    Parameters:\n",
    "        model (torch.nn.Module): Trained model.\n",
    "        train_loss (list): List of training losses.\n",
    "        test_log (list): List containing tuples/logs of test accuracy and loss.\n",
    "        all_output_gradients (list): List of output gradients collected during training.\n",
    "    \"\"\"\n",
    "    save_directory = os.path.expanduser('~/Desktop/FL/src/Inversion_Attack_Results/100 epoch')\n",
    "    if not os.path.exists(save_directory):\n",
    "        os.makedirs(save_directory)\n",
    "\n",
    "    noise_multiplier_str = f'{args.noise_multiplier:.2f}'.replace('.', '_')\n",
    "    file_path = os.path.join(save_directory, f'Gaussian_noise_multiplier_{noise_multiplier_str}.pth')\n",
    "\n",
    "    results = {\n",
    "        'model_state_dict': model.state_dict(),  # Save model parameters\n",
    "        'train_loss': train_loss,\n",
    "        'test_accuracy': [log[0] for log in test_log],\n",
    "        'test_loss': [log[1] for log in test_log],\n",
    "        'all_output_gradients': all_output_gradients  # Save output gradients\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        torch.save(results, file_path)\n",
    "        print(f\"Results saved to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save results: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be59ea49-77fb-44b1-a707-abc22fc2162a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "\n",
    "# Initialize the parser\n",
    "parser = argparse.ArgumentParser(description='Federated Learning with Differential Privacy')\n",
    "\n",
    "parser.add_argument('--epochs', type=int, default=100, help=\"number of rounds of training\")\n",
    "parser.add_argument('--num_users', type=int, default=10, help=\"number of users: K\")\n",
    "parser.add_argument('--frac', type=float, default=0.5, help='the fraction of clients')\n",
    "parser.add_argument('--local_ep', type=int, default=5, help=\"the number of local epochs: E\")\n",
    "parser.add_argument('--local_bs', type=int, default=50, help=\"local batch size: B\") \n",
    "\n",
    "# optimizer arguments\n",
    "parser.add_argument('--optimizer', type=str, default='sgd', help=\"type of optimizer\")\n",
    "parser.add_argument('--lr', type=float, default=0.002, help='learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, help='SGD momentum (default: 0.0)')\n",
    "\n",
    "# model arguments\n",
    "parser.add_argument('--model', type=str, default='cnn', help='model name')\n",
    "parser.add_argument('--activation', type=str, default=\"relu\", help='SGD momentum (default: 0.0)')\n",
    "\n",
    "## DP arguments\n",
    "parser.add_argument('--withDP', type=int, default= 1, help='WithDP')\n",
    "parser.add_argument('--max_grad_norm', type=float, default= 1, help='DP MAX_GRAD_NORM')\n",
    "parser.add_argument('--delta', type=float, default= 1e-4, help='DP DELTA')\n",
    "parser.add_argument('--virtual_batch_size', type=int, default= 50, help='DP VIRTUAL_BATCH_SIZE')\n",
    "parser.add_argument('--sampling_prob', type=int, default= 0.001 , help='sampling_prob') \n",
    "parser.add_argument('--noise_multiplier', type=float, default=0.43, help='DP NOISE_MULTIPLIER')\n",
    "\n",
    "# dataset arguments\n",
    "parser.add_argument('--dataset', type=str, default='dr', help=\"name of dataset\")\n",
    "parser.add_argument('--num_classes', type=int, default=5, help=\"number of classes\")\n",
    "parser.add_argument('--device', default='cuda:0', help=\"To use cuda, set to a specific GPU ID. Default set to use CPU.\")\n",
    "parser.add_argument('--iid', type=int, default=1, help='Default set to IID. Set to 0 for non-IID.')\n",
    "parser.add_argument('--unequal', type=int, default=0, help='whether to use unequal data splits for non-i.i.d setting (use 0 for equal splits)')\n",
    "parser.add_argument('--sub_dataset_size', type=int, default=-1, help='To reduce original data to a smaller dataset. For experimental purposes.')\n",
    "parser.add_argument('--local_test_split', type=float, default=0.3, help='local_test_split')                    \n",
    "parser.add_argument('--dr_from_np', type=float, default=1, help='for diabetic_retinopathy dataset')                    \n",
    "parser.add_argument('--exp_name', type=str, default=\"exp_results\", help=\"The name of current experiment for logging.\")\n",
    "\n",
    "# Parse the arguments, ignoring unknown ones\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "# Setting the device to use GPU0 explicitly if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8a206f7-fa90-4bc7-a1cc-bc6ca8d6c584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train dataset length: 2931\n",
      "Test dataset length: 731\n",
      "First training image shape: torch.Size([3, 224, 224])\n",
      "First training image type: torch.float32\n",
      "First training label type: <class 'torch.Tensor'>\n",
      "First testing image shape: torch.Size([3, 224, 224])\n",
      "First testing image type: torch.float32\n",
      "First testing label type: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and user groups\n",
    "train_dataset, test_dataset, user_groups = get_dataset(args)\n",
    "print(\"Train dataset length:\", len(train_dataset))\n",
    "print(\"Test dataset length:\", len(test_dataset))\n",
    "\n",
    "\n",
    "# Shape and Type of dataset\n",
    "# Inspect the first sample from the training dataset\n",
    "train_features, train_labels = train_dataset[0]\n",
    "print(\"First training image shape:\", train_features.shape)\n",
    "print(\"First training image type:\", train_features.dtype)\n",
    "print(\"First training label type:\", type(train_labels))\n",
    "\n",
    "# Inspect the first sample from the testing dataset\n",
    "test_features, test_labels = test_dataset[0]\n",
    "print(\"First testing image shape:\", test_features.shape)\n",
    "print(\"First testing image type:\", test_features.dtype)\n",
    "print(\"First testing label type:\", type(test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3693285b-cb53-477a-87ee-ddc2cf8b2d36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 111, 111]           1,792\n",
      "              ReLU-2         [-1, 64, 111, 111]               0\n",
      "         MaxPool2d-3           [-1, 64, 55, 55]               0\n",
      "            Conv2d-4           [-1, 16, 55, 55]           1,040\n",
      "              ReLU-5           [-1, 16, 55, 55]               0\n",
      "            Conv2d-6           [-1, 64, 55, 55]           1,088\n",
      "              ReLU-7           [-1, 64, 55, 55]               0\n",
      "            Conv2d-8           [-1, 64, 55, 55]           9,280\n",
      "              ReLU-9           [-1, 64, 55, 55]               0\n",
      "             Fire-10          [-1, 128, 55, 55]               0\n",
      "           Conv2d-11           [-1, 16, 55, 55]           2,064\n",
      "             ReLU-12           [-1, 16, 55, 55]               0\n",
      "           Conv2d-13           [-1, 64, 55, 55]           1,088\n",
      "             ReLU-14           [-1, 64, 55, 55]               0\n",
      "           Conv2d-15           [-1, 64, 55, 55]           9,280\n",
      "             ReLU-16           [-1, 64, 55, 55]               0\n",
      "             Fire-17          [-1, 128, 55, 55]               0\n",
      "        MaxPool2d-18          [-1, 128, 27, 27]               0\n",
      "           Conv2d-19           [-1, 32, 27, 27]           4,128\n",
      "             ReLU-20           [-1, 32, 27, 27]               0\n",
      "           Conv2d-21          [-1, 128, 27, 27]           4,224\n",
      "             ReLU-22          [-1, 128, 27, 27]               0\n",
      "           Conv2d-23          [-1, 128, 27, 27]          36,992\n",
      "             ReLU-24          [-1, 128, 27, 27]               0\n",
      "             Fire-25          [-1, 256, 27, 27]               0\n",
      "           Conv2d-26           [-1, 32, 27, 27]           8,224\n",
      "             ReLU-27           [-1, 32, 27, 27]               0\n",
      "           Conv2d-28          [-1, 128, 27, 27]           4,224\n",
      "             ReLU-29          [-1, 128, 27, 27]               0\n",
      "           Conv2d-30          [-1, 128, 27, 27]          36,992\n",
      "             ReLU-31          [-1, 128, 27, 27]               0\n",
      "             Fire-32          [-1, 256, 27, 27]               0\n",
      "        MaxPool2d-33          [-1, 256, 13, 13]               0\n",
      "           Conv2d-34           [-1, 48, 13, 13]          12,336\n",
      "             ReLU-35           [-1, 48, 13, 13]               0\n",
      "           Conv2d-36          [-1, 192, 13, 13]           9,408\n",
      "             ReLU-37          [-1, 192, 13, 13]               0\n",
      "           Conv2d-38          [-1, 192, 13, 13]          83,136\n",
      "             ReLU-39          [-1, 192, 13, 13]               0\n",
      "             Fire-40          [-1, 384, 13, 13]               0\n",
      "           Conv2d-41           [-1, 48, 13, 13]          18,480\n",
      "             ReLU-42           [-1, 48, 13, 13]               0\n",
      "           Conv2d-43          [-1, 192, 13, 13]           9,408\n",
      "             ReLU-44          [-1, 192, 13, 13]               0\n",
      "           Conv2d-45          [-1, 192, 13, 13]          83,136\n",
      "             ReLU-46          [-1, 192, 13, 13]               0\n",
      "             Fire-47          [-1, 384, 13, 13]               0\n",
      "           Conv2d-48           [-1, 64, 13, 13]          24,640\n",
      "             ReLU-49           [-1, 64, 13, 13]               0\n",
      "           Conv2d-50          [-1, 256, 13, 13]          16,640\n",
      "             ReLU-51          [-1, 256, 13, 13]               0\n",
      "           Conv2d-52          [-1, 256, 13, 13]         147,712\n",
      "             ReLU-53          [-1, 256, 13, 13]               0\n",
      "             Fire-54          [-1, 512, 13, 13]               0\n",
      "           Conv2d-55           [-1, 64, 13, 13]          32,832\n",
      "             ReLU-56           [-1, 64, 13, 13]               0\n",
      "           Conv2d-57          [-1, 256, 13, 13]          16,640\n",
      "             ReLU-58          [-1, 256, 13, 13]               0\n",
      "           Conv2d-59          [-1, 256, 13, 13]         147,712\n",
      "             ReLU-60          [-1, 256, 13, 13]               0\n",
      "             Fire-61          [-1, 512, 13, 13]               0\n",
      "          Dropout-62          [-1, 512, 13, 13]               0\n",
      "           Conv2d-63            [-1, 5, 13, 13]           2,565\n",
      "             ReLU-64            [-1, 5, 13, 13]               0\n",
      "AdaptiveAvgPool2d-65              [-1, 5, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 725,061\n",
      "Trainable params: 725,061\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 51.19\n",
      "Params size (MB): 2.77\n",
      "Estimated Total Size (MB): 54.53\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import squeezenet1_1, SqueezeNet1_1_Weights\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "# DEVICE SETUP\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# BUILD MODEL\n",
    "weights = SqueezeNet1_1_Weights.IMAGENET1K_V1  # Load the predefined weights\n",
    "global_model = squeezenet1_1(weights=weights)  # Initialize the model with weights\n",
    "global_model.classifier[1] = nn.Conv2d(512, 5, kernel_size=(1,1), stride=(1,1))  # Modify the classifier for 5 classes\n",
    "global_model.num_classes = 5\n",
    "global_model.to(device)  # Move the model to the appropriate device\n",
    "summary(global_model, input_size=(3, 224, 224), device=device.type)  # Display the model summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69d6f771-2556-4e5a-ae97-fd9d68a08101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Models and Optimizers\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "local_models = []\n",
    "local_optimizers = []\n",
    "local_privacy_engine = []\n",
    "\n",
    "for u in range(args.num_users):\n",
    "    local_models.append(copy.deepcopy(global_model))\n",
    "\n",
    "    if args.optimizer == 'sgd':\n",
    "        optimizer = torch.optim.SGD(local_models[u].parameters(), lr=args.lr, \n",
    "                                    momentum=args.momentum)        \n",
    "    elif args.optimizer == 'adam':\n",
    "        optimizer = torch.optim.Adam(local_models[u].parameters(), lr=args.lr)             \n",
    "\n",
    "    if args.withDP:\n",
    "        privacy_engine = PrivacyEngine(\n",
    "            local_models[u],\n",
    "            batch_size = args.virtual_batch_size,\n",
    "            sample_size=len(user_groups[u]),\n",
    "            alphas=[1 + x / 10.0 for x in range(1, 100)] + list(range(12, 64)),\n",
    "            noise_multiplier = args.noise_multiplier,\n",
    "            max_grad_norm =  args.max_grad_norm,\n",
    "        )\n",
    "        \n",
    "        privacy_engine.attach(optimizer)            \n",
    "        local_privacy_engine.append(privacy_engine)\n",
    "\n",
    "    local_optimizers.append(optimizer)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcf988f4-2559-453a-b4a0-1cfac129fb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's already Valid!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DP Model Compatibility \n",
    "\n",
    "if args.withDP:\n",
    "    try:\n",
    "        inspector = DPModelInspector()\n",
    "        inspector.validate(global_model)\n",
    "        print(\"Model's already Valid!\\n\")\n",
    "    except:\n",
    "        global_model = module_modification.convert_batchnorm_modules(global_model)\n",
    "        inspector = DPModelInspector()\n",
    "        print(f\"Is the model valid? {inspector.validate(global_model)}\")\n",
    "        print(\"Model is convereted to be Valid!\\n\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee3e6c72-4e51-4d16-a641-cd1efdc8eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Models and Optimizers \n",
    "u_steps = np.zeros(args.num_users)  \n",
    "epsilons = np.zeros(args.num_users)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5762edf7-78b1-4dba-bffb-5748accec41c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "Average train loss: 1.5676665776968002\n",
      "Test Accuracy: 60.88%\n",
      "epsilons: max 29.68,  mean 14.84, std 14.84\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 2\n",
      "Average train loss: 1.0838954734802246\n",
      "Test Accuracy: 55.13%\n",
      "epsilons: max 41.57,  mean 22.56, std 18.93\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 3\n",
      "Average train loss: 1.191592583656311\n",
      "Test Accuracy: 62.38%\n",
      "epsilons: max 51.89,  mean 33.53, std 14.15\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 4\n",
      "Average train loss: 1.0615926972031593\n",
      "Test Accuracy: 66.07%\n",
      "epsilons: max 60.86,  mean 39.02, std 15.91\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 5\n",
      "Average train loss: 1.003853984475136\n",
      "Test Accuracy: 67.31%\n",
      "epsilons: max 68.98,  mean 45.63, std 13.64\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 6\n",
      "Average train loss: 1.040381169319153\n",
      "Test Accuracy: 67.44%\n",
      "epsilons: max 77.11,  mean 50.59, std 14.35\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 7\n",
      "Average train loss: 1.0990940278768542\n",
      "Test Accuracy: 66.76%\n",
      "epsilons: max 77.11,  mean 55.18, std 15.03\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 8\n",
      "Average train loss: 1.0009190782904624\n",
      "Test Accuracy: 67.03%\n",
      "epsilons: max 85.23,  mean 59.70, std 15.75\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 9\n",
      "Average train loss: 1.0616299891471863\n",
      "Test Accuracy: 67.44%\n",
      "epsilons: max 93.35,  mean 64.36, std 15.29\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 10\n",
      "Average train loss: 1.0995327854156494\n",
      "Test Accuracy: 67.72%\n",
      "epsilons: max 93.35,  mean 68.68, std 15.06\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 11\n",
      "Average train loss: 1.0738921552896499\n",
      "Test Accuracy: 67.99%\n",
      "epsilons: max 101.26,  mean 72.72, std 16.46\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 12\n",
      "Average train loss: 1.0559582579135895\n",
      "Test Accuracy: 68.67%\n",
      "epsilons: max 101.26,  mean 76.78, std 16.84\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 13\n",
      "Average train loss: 0.9993599653244021\n",
      "Test Accuracy: 68.95%\n",
      "epsilons: max 101.26,  mean 80.82, std 18.12\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 14\n",
      "Average train loss: 1.0812355560064315\n",
      "Test Accuracy: 69.08%\n",
      "epsilons: max 101.26,  mean 84.84, std 19.13\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 15\n",
      "Average train loss: 1.046739319562912\n",
      "Test Accuracy: 69.08%\n",
      "epsilons: max 107.70,  mean 88.54, std 20.58\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 16\n",
      "Average train loss: 1.0342981165647507\n",
      "Test Accuracy: 68.54%\n",
      "epsilons: max 114.13,  mean 92.24, std 20.88\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 17\n",
      "Average train loss: 1.0472630214691163\n",
      "Test Accuracy: 69.36%\n",
      "epsilons: max 120.57,  mean 95.78, std 22.15\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 18\n",
      "Average train loss: 1.0559773594141006\n",
      "Test Accuracy: 69.63%\n",
      "epsilons: max 127.00,  mean 99.38, std 21.51\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 19\n",
      "Average train loss: 1.1054923248291015\n",
      "Test Accuracy: 70.04%\n",
      "epsilons: max 133.44,  mean 103.00, std 21.13\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 20\n",
      "Average train loss: 1.1777851569652558\n",
      "Test Accuracy: 70.18%\n",
      "epsilons: max 133.44,  mean 106.39, std 20.75\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 21\n",
      "Average train loss: 1.1272247582674026\n",
      "Test Accuracy: 69.49%\n",
      "epsilons: max 139.87,  mean 109.61, std 22.52\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 22\n",
      "Average train loss: 1.1109926211833954\n",
      "Test Accuracy: 70.31%\n",
      "epsilons: max 139.87,  mean 113.16, std 20.75\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 23\n",
      "Average train loss: 1.189366407394409\n",
      "Test Accuracy: 70.45%\n",
      "epsilons: max 139.87,  mean 116.72, std 18.40\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 24\n",
      "Average train loss: 1.223793724179268\n",
      "Test Accuracy: 69.90%\n",
      "epsilons: max 139.87,  mean 120.27, std 16.25\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 25\n",
      "Average train loss: 1.1859173345565797\n",
      "Test Accuracy: 70.73%\n",
      "epsilons: max 139.87,  mean 123.78, std 13.57\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 26\n",
      "Average train loss: 1.1607168358564377\n",
      "Test Accuracy: 70.86%\n",
      "epsilons: max 146.31,  mean 127.00, std 12.54\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 27\n",
      "Average train loss: 1.187538664638996\n",
      "Test Accuracy: 71.41%\n",
      "epsilons: max 152.74,  mean 130.22, std 13.27\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 28\n",
      "Average train loss: 1.2535988080501557\n",
      "Test Accuracy: 70.86%\n",
      "epsilons: max 152.74,  mean 133.44, std 11.87\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 29\n",
      "Average train loss: 1.2110542511940001\n",
      "Test Accuracy: 70.86%\n",
      "epsilons: max 159.18,  mean 136.65, std 11.60\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 30\n",
      "Average train loss: 1.2295777517557143\n",
      "Test Accuracy: 71.68%\n",
      "epsilons: max 165.61,  mean 139.87, std 12.87\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 31\n",
      "Average train loss: 1.230510822236538\n",
      "Test Accuracy: 71.00%\n",
      "epsilons: max 172.05,  mean 143.09, std 13.57\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 32\n",
      "Average train loss: 1.2603912580013275\n",
      "Test Accuracy: 71.14%\n",
      "epsilons: max 172.05,  mean 146.31, std 14.95\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 33\n",
      "Average train loss: 1.2287184727191924\n",
      "Test Accuracy: 71.14%\n",
      "epsilons: max 178.48,  mean 149.52, std 15.02\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 34\n",
      "Average train loss: 1.1861369740962981\n",
      "Test Accuracy: 71.00%\n",
      "epsilons: max 184.91,  mean 152.74, std 16.02\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 35\n",
      "Average train loss: 1.367227242588997\n",
      "Test Accuracy: 71.14%\n",
      "epsilons: max 191.35,  mean 155.96, std 16.84\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 36\n",
      "Average train loss: 1.2694725424051287\n",
      "Test Accuracy: 71.41%\n",
      "epsilons: max 191.35,  mean 159.18, std 15.50\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 37\n",
      "Average train loss: 1.2869822323322295\n",
      "Test Accuracy: 71.27%\n",
      "epsilons: max 197.78,  mean 162.39, std 16.59\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 38\n",
      "Average train loss: 1.2218569847941398\n",
      "Test Accuracy: 70.86%\n",
      "epsilons: max 204.22,  mean 165.61, std 18.65\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 39\n",
      "Average train loss: 1.3256535571813584\n",
      "Test Accuracy: 71.14%\n",
      "epsilons: max 210.65,  mean 168.83, std 19.14\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 40\n",
      "Average train loss: 1.254597913324833\n",
      "Test Accuracy: 71.14%\n",
      "epsilons: max 217.09,  mean 172.05, std 20.14\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 41\n",
      "Average train loss: 1.2985947707295418\n",
      "Test Accuracy: 70.73%\n",
      "epsilons: max 223.52,  mean 175.26, std 21.77\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 42\n",
      "Average train loss: 1.2533606052398683\n",
      "Test Accuracy: 71.00%\n",
      "epsilons: max 229.96,  mean 178.48, std 22.10\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 43\n",
      "Average train loss: 1.2511949265003204\n",
      "Test Accuracy: 71.27%\n",
      "epsilons: max 236.39,  mean 181.70, std 22.89\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 44\n",
      "Average train loss: 1.383590191602707\n",
      "Test Accuracy: 71.41%\n",
      "epsilons: max 236.39,  mean 184.91, std 21.34\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 45\n",
      "Average train loss: 1.217784916162491\n",
      "Test Accuracy: 71.96%\n",
      "epsilons: max 236.39,  mean 188.13, std 20.60\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 46\n",
      "Average train loss: 1.2177629894018174\n",
      "Test Accuracy: 71.14%\n",
      "epsilons: max 242.83,  mean 191.35, std 21.34\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 47\n",
      "Average train loss: 1.212695742249489\n",
      "Test Accuracy: 71.00%\n",
      "epsilons: max 242.83,  mean 194.57, std 21.00\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 48\n",
      "Average train loss: 1.2734157755970954\n",
      "Test Accuracy: 71.00%\n",
      "epsilons: max 249.26,  mean 197.78, std 22.10\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 49\n",
      "Average train loss: 1.3509511160850525\n",
      "Test Accuracy: 71.14%\n",
      "epsilons: max 249.26,  mean 201.00, std 21.20\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 50\n",
      "Average train loss: 1.267009015083313\n",
      "Test Accuracy: 71.55%\n",
      "epsilons: max 249.26,  mean 204.22, std 21.73\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 51\n",
      "Average train loss: 1.290681511759758\n",
      "Test Accuracy: 71.27%\n",
      "epsilons: max 255.70,  mean 207.44, std 22.71\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 52\n",
      "Average train loss: 1.2561422625184058\n",
      "Test Accuracy: 71.27%\n",
      "epsilons: max 262.13,  mean 210.65, std 24.08\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 53\n",
      "Average train loss: 1.2682386690378187\n",
      "Test Accuracy: 71.41%\n",
      "epsilons: max 268.09,  mean 213.82, std 25.52\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 54\n",
      "Average train loss: 1.2806964498758315\n",
      "Test Accuracy: 71.96%\n",
      "epsilons: max 273.22,  mean 216.91, std 25.83\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 55\n",
      "Average train loss: 1.280318711400032\n",
      "Test Accuracy: 71.68%\n",
      "epsilons: max 273.22,  mean 220.13, std 25.89\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 56\n",
      "Average train loss: 1.256610068678856\n",
      "Test Accuracy: 71.82%\n",
      "epsilons: max 278.34,  mean 223.21, std 25.22\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 57\n",
      "Average train loss: 1.2484215635061264\n",
      "Test Accuracy: 71.82%\n",
      "epsilons: max 283.47,  mean 226.30, std 26.05\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 58\n",
      "Average train loss: 1.3067054721713065\n",
      "Test Accuracy: 71.55%\n",
      "epsilons: max 283.47,  mean 229.52, std 24.76\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 59\n",
      "Average train loss: 1.2906159946322442\n",
      "Test Accuracy: 71.27%\n",
      "epsilons: max 288.59,  mean 232.60, std 25.60\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 60\n",
      "Average train loss: 1.4035775691270829\n",
      "Test Accuracy: 71.55%\n",
      "epsilons: max 288.59,  mean 235.82, std 25.15\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 61\n",
      "Average train loss: 1.3138301768898963\n",
      "Test Accuracy: 71.55%\n",
      "epsilons: max 293.71,  mean 238.91, std 25.48\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 62\n",
      "Average train loss: 1.3179931226372719\n",
      "Test Accuracy: 71.55%\n",
      "epsilons: max 293.71,  mean 242.08, std 25.80\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 63\n",
      "Average train loss: 1.3094698649644851\n",
      "Test Accuracy: 71.27%\n",
      "epsilons: max 293.71,  mean 245.16, std 25.13\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 64\n",
      "Average train loss: 1.3614597660303116\n",
      "Test Accuracy: 71.55%\n",
      "epsilons: max 293.71,  mean 248.38, std 24.87\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 65\n",
      "Average train loss: 1.2887192970514296\n",
      "Test Accuracy: 71.68%\n",
      "epsilons: max 293.71,  mean 251.37, std 26.23\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 66\n",
      "Average train loss: 1.281485885977745\n",
      "Test Accuracy: 71.96%\n",
      "epsilons: max 298.84,  mean 254.20, std 27.16\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 67\n",
      "Average train loss: 1.3965811759233475\n",
      "Test Accuracy: 71.96%\n",
      "epsilons: max 303.96,  mean 256.97, std 28.05\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 68\n",
      "Average train loss: 1.3626844376325606\n",
      "Test Accuracy: 72.50%\n",
      "epsilons: max 309.09,  mean 259.93, std 27.54\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 69\n",
      "Average train loss: 1.2843221098184585\n",
      "Test Accuracy: 72.09%\n",
      "epsilons: max 314.21,  mean 262.88, std 27.21\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 70\n",
      "Average train loss: 1.3039877951145171\n",
      "Test Accuracy: 72.50%\n",
      "epsilons: max 319.33,  mean 265.97, std 25.81\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 71\n",
      "Average train loss: 1.3449128264188766\n",
      "Test Accuracy: 72.23%\n",
      "epsilons: max 324.46,  mean 268.88, std 25.56\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 72\n",
      "Average train loss: 1.3040809190273286\n",
      "Test Accuracy: 71.96%\n",
      "epsilons: max 329.58,  mean 271.44, std 27.30\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 73\n",
      "Average train loss: 1.3453048515319825\n",
      "Test Accuracy: 72.09%\n",
      "epsilons: max 334.71,  mean 274.27, std 28.12\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 74\n",
      "Average train loss: 1.3297283232212065\n",
      "Test Accuracy: 72.37%\n",
      "epsilons: max 339.83,  mean 277.09, std 28.03\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 75\n",
      "Average train loss: 1.2946527343988419\n",
      "Test Accuracy: 72.50%\n",
      "epsilons: max 344.95,  mean 280.00, std 27.90\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 76\n",
      "Average train loss: 1.3444962322711944\n",
      "Test Accuracy: 72.50%\n",
      "epsilons: max 344.95,  mean 282.77, std 27.02\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 77\n",
      "Average train loss: 1.3124049556255342\n",
      "Test Accuracy: 72.23%\n",
      "epsilons: max 350.08,  mean 285.47, std 27.91\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 78\n",
      "Average train loss: 1.3406965646147728\n",
      "Test Accuracy: 71.96%\n",
      "epsilons: max 350.08,  mean 288.16, std 27.19\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 79\n",
      "Average train loss: 1.3509262311458587\n",
      "Test Accuracy: 72.23%\n",
      "epsilons: max 350.08,  mean 290.94, std 25.63\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 80\n",
      "Average train loss: 1.2566565519571304\n",
      "Test Accuracy: 72.23%\n",
      "epsilons: max 355.20,  mean 293.50, std 26.33\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 81\n",
      "Average train loss: 1.4371612137556076\n",
      "Test Accuracy: 72.37%\n",
      "epsilons: max 360.33,  mean 296.06, std 26.87\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 82\n",
      "Average train loss: 1.3189301231503485\n",
      "Test Accuracy: 72.37%\n",
      "epsilons: max 365.45,  mean 298.75, std 27.42\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 83\n",
      "Average train loss: 1.3737790942192079\n",
      "Test Accuracy: 72.23%\n",
      "epsilons: max 365.45,  mean 301.32, std 27.06\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 84\n",
      "Average train loss: 1.302929121851921\n",
      "Test Accuracy: 72.23%\n",
      "epsilons: max 370.57,  mean 303.88, std 27.72\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 85\n",
      "Average train loss: 1.414392325878143\n",
      "Test Accuracy: 72.37%\n",
      "epsilons: max 375.70,  mean 306.52, std 28.09\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 86\n",
      "Average train loss: 1.4173309287428857\n",
      "Test Accuracy: 72.37%\n",
      "epsilons: max 375.70,  mean 309.09, std 27.59\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 87\n",
      "Average train loss: 1.3695142650604246\n",
      "Test Accuracy: 72.50%\n",
      "epsilons: max 380.82,  mean 311.65, std 28.74\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 88\n",
      "Average train loss: 1.3486077946424484\n",
      "Test Accuracy: 72.23%\n",
      "epsilons: max 380.82,  mean 314.21, std 28.16\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 89\n",
      "Average train loss: 1.263247059583664\n",
      "Test Accuracy: 72.37%\n",
      "epsilons: max 380.82,  mean 316.77, std 27.71\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 90\n",
      "Average train loss: 1.2913419884443285\n",
      "Test Accuracy: 72.64%\n",
      "epsilons: max 385.95,  mean 319.33, std 27.59\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 91\n",
      "Average train loss: 1.269258067011833\n",
      "Test Accuracy: 72.64%\n",
      "epsilons: max 391.07,  mean 321.90, std 28.37\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 92\n",
      "Average train loss: 1.305598230957985\n",
      "Test Accuracy: 72.50%\n",
      "epsilons: max 396.19,  mean 324.46, std 29.44\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 93\n",
      "Average train loss: 1.3109798604249954\n",
      "Test Accuracy: 72.78%\n",
      "epsilons: max 401.32,  mean 327.02, std 30.25\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 94\n",
      "Average train loss: 1.4194776353240013\n",
      "Test Accuracy: 72.50%\n",
      "epsilons: max 401.32,  mean 329.58, std 29.88\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 95\n",
      "Average train loss: 1.3794294589757918\n",
      "Test Accuracy: 72.09%\n",
      "epsilons: max 401.32,  mean 332.14, std 28.83\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 96\n",
      "Average train loss: 1.3330638885498047\n",
      "Test Accuracy: 72.78%\n",
      "epsilons: max 406.44,  mean 334.71, std 29.17\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 97\n",
      "Average train loss: 1.346408737897873\n",
      "Test Accuracy: 72.50%\n",
      "epsilons: max 406.44,  mean 337.27, std 28.55\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 98\n",
      "Average train loss: 1.3302344399690629\n",
      "Test Accuracy: 72.37%\n",
      "epsilons: max 406.44,  mean 339.83, std 28.71\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 99\n",
      "Average train loss: 1.2761474627256395\n",
      "Test Accuracy: 72.50%\n",
      "epsilons: max 411.57,  mean 342.39, std 30.42\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n",
      "\n",
      "Epoch: 100\n",
      "Average train loss: 1.3634057247638702\n",
      "Test Accuracy: 72.50%\n",
      "epsilons: max 411.57,  mean 344.95, std 30.05\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/100 epoch/Gaussian_noise_multiplier_0_43.pth\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "train_loss = []\n",
    "test_log = []\n",
    "epsilon_log = []\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    # Sample the users\n",
    "    idxs_users = np.random.choice(range(args.num_users),\n",
    "                                  max(int(args.frac * args.num_users), 1),\n",
    "                                  replace=False)\n",
    "\n",
    "    local_weights, local_losses = [], []\n",
    "    all_output_gradients = []\n",
    "    \n",
    "    for u in idxs_users:\n",
    "        local_model = LocalUpdate(args=args, dataset=train_dataset, u_id=u, idxs=user_groups[u])\n",
    "        w, loss, u_step, epsilon, user_output_gradients = local_model.update_weights(\n",
    "                                                model=copy.deepcopy(global_model),\n",
    "                                                global_round=epoch,\n",
    "                                                u_step=u_steps[u])\n",
    "        local_weights.append(copy.deepcopy(w))\n",
    "        local_losses.append(copy.deepcopy(loss))\n",
    "        all_output_gradients.extend(user_output_gradients)  # Collect output gradients from each user\n",
    "        u_steps[u] = u_step\n",
    "        epsilons[u] = epsilon\n",
    "\n",
    "    # Update global weights\n",
    "    global_weights = average_weights(local_weights)\n",
    "\n",
    "    # Load updated global weights\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    loss_avg = sum(local_losses) / len(local_losses)\n",
    "    train_loss.append(loss_avg)\n",
    "\n",
    "    _acc, _loss = test_inference(args, global_model, test_dataset)\n",
    "    test_log.append([_acc, _loss])\n",
    "\n",
    "    if args.withDP:\n",
    "        epsilon_log.append(list(epsilons))\n",
    "    else:\n",
    "        epsilon_log = None\n",
    "\n",
    "    logging(args, epoch, train_loss, test_log, epsilon_log)\n",
    "\n",
    "    # Save results including gradients\n",
    "    save_results(global_model, train_loss, test_log, all_output_gradients)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
