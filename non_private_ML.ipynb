{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fcb4a20-bd8f-40bd-8754-7e639fc1e47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mahsa/Desktop/FL/src\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('Desktop/src')\n",
    "\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a25f0f-8291-408e-9606-e9b7236a752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "from options import args_parser\n",
    "from update_s2 import LocalUpdate\n",
    "from utils import test_inference\n",
    "from models import CNNMnistRelu, CNNMnistTanh\n",
    "from models import CNNFashion_MnistRelu, CNNFashion_MnistTanh\n",
    "from models import CNNCifar10Relu, CNNCifar10Tanh\n",
    "from utils import average_weights, exp_details\n",
    "from datasets import get_dataset\n",
    "from torchvision import models\n",
    "from opacus.dp_model_inspector import DPModelInspector\n",
    "from opacus.utils import module_modification\n",
    "from opacus import PrivacyEngine\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0721c53e-7c0e-416c-80b6-0d6d6f8d701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(model, train_loss, test_log, all_output_gradients):\n",
    "    \"\"\"\n",
    "    Saves the training results, including the model state, losses, test metrics, and output gradients,\n",
    "    using torch.save for better compatibility with PyTorch objects.\n",
    "    \n",
    "    Parameters:\n",
    "        model (torch.nn.Module): Trained model.\n",
    "        train_loss (list): List of training losses.\n",
    "        test_log (list): List containing tuples/logs of test accuracy and loss.\n",
    "        all_output_gradients (list): List of output gradients collected during training.\n",
    "    \"\"\"\n",
    "    save_directory = os.path.expanduser('~/Desktop/FL/src/Inversion_Attack_Results')\n",
    "    if not os.path.exists(save_directory):\n",
    "        os.makedirs(save_directory)\n",
    "\n",
    "    file_path = os.path.join(save_directory, f'non_private_ML.pth')\n",
    "\n",
    "    results = {\n",
    "        'model_state_dict': model.state_dict(),  # Save model parameters\n",
    "        'train_loss': train_loss,\n",
    "        'test_accuracy': [log[0] for log in test_log],\n",
    "        'test_loss': [log[1] for log in test_log],\n",
    "        'all_output_gradients': all_output_gradients  # Save output gradients\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        torch.save(results, file_path)\n",
    "        print(f\"Results saved to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save results: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79384fcf-7ecc-4658-b417-051125475085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "# Initialize the parser\n",
    "parser = argparse.ArgumentParser(description='Federated Learning with Differential Privacy')\n",
    "\n",
    "parser.add_argument('--epochs', type=int, default=100, help=\"number of rounds of training\")\n",
    "parser.add_argument('--num_users', type=int, default=1, help=\"number of users: K\")\n",
    "parser.add_argument('--frac', type=float, default=1, help='the fraction of clients')\n",
    "parser.add_argument('--local_ep', type=int, default=1, help=\"the number of local epochs: E\")\n",
    "parser.add_argument('--local_bs', type=int, default=50, help=\"local batch size: B\") \n",
    "\n",
    "# optimizer arguments\n",
    "parser.add_argument('--optimizer', type=str, default='sgd', help=\"type of optimizer\") \n",
    "parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, help='SGD momentum (default: 0.0)')\n",
    "\n",
    "# model arguments\n",
    "parser.add_argument('--model', type=str, default='cnn', help='model name')\n",
    "parser.add_argument('--activation', type=str, default=\"relu\", help='SGD momentum (default: 0.0)')\n",
    "\n",
    "## DP arguments\n",
    "parser.add_argument('--withDP', type=int, default=0, help='WithDP')\n",
    "\n",
    "# dataset arguments\n",
    "parser.add_argument('--dataset', type=str, default='dr', help=\"name of dataset\")\n",
    "parser.add_argument('--num_classes', type=int, default=5, help=\"number of classes\")\n",
    "parser.add_argument('--device', default='cuda:0', help=\"To use cuda, set to a specific GPU ID. Default set to use CPU.\")\n",
    "parser.add_argument('--iid', type=int, default=1,help='Default set to IID. Set to 0 for non-IID.')\n",
    "parser.add_argument('--unequal', type=int, default=0,help='whether to use unequal data splits for non-i.i.d setting (use 0 for equal splits)')\n",
    "parser.add_argument('--sub_dataset_size', type=int, default=-1, help='To reduce original data to a smaller dataset. For experimental purposes.')\n",
    "\n",
    "parser.add_argument('--local_test_split', type=float, default=0.30, help='local_test_split')                    \n",
    "parser.add_argument('--dr_from_np', type=float, default=1, help='for diabetic_retinopathy dataset')                    \n",
    "parser.add_argument('--exp_name', type=str, default=\"exp_results\", help=\"The name of current experiment for logging.\")\n",
    "\n",
    "# Parse the arguments, ignoring unknown ones\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "# Setting the device to use GPU0 explicitly if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f21c4b8-0c9d-4bcb-926c-3eeba7b94702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train dataset length: 2931\n",
      "Test dataset length: 731\n",
      "First training image shape: torch.Size([3, 224, 224])\n",
      "First training image type: torch.float32\n",
      "First training label type: <class 'torch.Tensor'>\n",
      "First testing image shape: torch.Size([3, 224, 224])\n",
      "First testing image type: torch.float32\n",
      "First testing label type: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and user groups\n",
    "train_dataset, test_dataset, user_groups = get_dataset(args)\n",
    "print(\"Train dataset length:\", len(train_dataset))\n",
    "print(\"Test dataset length:\", len(test_dataset))\n",
    "\n",
    "# Shape and Type of dataset\n",
    "# Inspect the first sample from the training dataset\n",
    "train_features, train_labels = train_dataset[0]\n",
    "print(\"First training image shape:\", train_features.shape)\n",
    "print(\"First training image type:\", train_features.dtype)\n",
    "print(\"First training label type:\", type(train_labels))\n",
    "\n",
    "# Inspect the first sample from the testing dataset\n",
    "test_features, test_labels = test_dataset[0]\n",
    "print(\"First testing image shape:\", test_features.shape)\n",
    "print(\"First testing image type:\", test_features.dtype)\n",
    "print(\"First testing label type:\", type(test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2f09f0c-ece5-47de-a758-6a303833e209",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 111, 111]           1,792\n",
      "              ReLU-2         [-1, 64, 111, 111]               0\n",
      "         MaxPool2d-3           [-1, 64, 55, 55]               0\n",
      "            Conv2d-4           [-1, 16, 55, 55]           1,040\n",
      "              ReLU-5           [-1, 16, 55, 55]               0\n",
      "            Conv2d-6           [-1, 64, 55, 55]           1,088\n",
      "              ReLU-7           [-1, 64, 55, 55]               0\n",
      "            Conv2d-8           [-1, 64, 55, 55]           9,280\n",
      "              ReLU-9           [-1, 64, 55, 55]               0\n",
      "             Fire-10          [-1, 128, 55, 55]               0\n",
      "           Conv2d-11           [-1, 16, 55, 55]           2,064\n",
      "             ReLU-12           [-1, 16, 55, 55]               0\n",
      "           Conv2d-13           [-1, 64, 55, 55]           1,088\n",
      "             ReLU-14           [-1, 64, 55, 55]               0\n",
      "           Conv2d-15           [-1, 64, 55, 55]           9,280\n",
      "             ReLU-16           [-1, 64, 55, 55]               0\n",
      "             Fire-17          [-1, 128, 55, 55]               0\n",
      "        MaxPool2d-18          [-1, 128, 27, 27]               0\n",
      "           Conv2d-19           [-1, 32, 27, 27]           4,128\n",
      "             ReLU-20           [-1, 32, 27, 27]               0\n",
      "           Conv2d-21          [-1, 128, 27, 27]           4,224\n",
      "             ReLU-22          [-1, 128, 27, 27]               0\n",
      "           Conv2d-23          [-1, 128, 27, 27]          36,992\n",
      "             ReLU-24          [-1, 128, 27, 27]               0\n",
      "             Fire-25          [-1, 256, 27, 27]               0\n",
      "           Conv2d-26           [-1, 32, 27, 27]           8,224\n",
      "             ReLU-27           [-1, 32, 27, 27]               0\n",
      "           Conv2d-28          [-1, 128, 27, 27]           4,224\n",
      "             ReLU-29          [-1, 128, 27, 27]               0\n",
      "           Conv2d-30          [-1, 128, 27, 27]          36,992\n",
      "             ReLU-31          [-1, 128, 27, 27]               0\n",
      "             Fire-32          [-1, 256, 27, 27]               0\n",
      "        MaxPool2d-33          [-1, 256, 13, 13]               0\n",
      "           Conv2d-34           [-1, 48, 13, 13]          12,336\n",
      "             ReLU-35           [-1, 48, 13, 13]               0\n",
      "           Conv2d-36          [-1, 192, 13, 13]           9,408\n",
      "             ReLU-37          [-1, 192, 13, 13]               0\n",
      "           Conv2d-38          [-1, 192, 13, 13]          83,136\n",
      "             ReLU-39          [-1, 192, 13, 13]               0\n",
      "             Fire-40          [-1, 384, 13, 13]               0\n",
      "           Conv2d-41           [-1, 48, 13, 13]          18,480\n",
      "             ReLU-42           [-1, 48, 13, 13]               0\n",
      "           Conv2d-43          [-1, 192, 13, 13]           9,408\n",
      "             ReLU-44          [-1, 192, 13, 13]               0\n",
      "           Conv2d-45          [-1, 192, 13, 13]          83,136\n",
      "             ReLU-46          [-1, 192, 13, 13]               0\n",
      "             Fire-47          [-1, 384, 13, 13]               0\n",
      "           Conv2d-48           [-1, 64, 13, 13]          24,640\n",
      "             ReLU-49           [-1, 64, 13, 13]               0\n",
      "           Conv2d-50          [-1, 256, 13, 13]          16,640\n",
      "             ReLU-51          [-1, 256, 13, 13]               0\n",
      "           Conv2d-52          [-1, 256, 13, 13]         147,712\n",
      "             ReLU-53          [-1, 256, 13, 13]               0\n",
      "             Fire-54          [-1, 512, 13, 13]               0\n",
      "           Conv2d-55           [-1, 64, 13, 13]          32,832\n",
      "             ReLU-56           [-1, 64, 13, 13]               0\n",
      "           Conv2d-57          [-1, 256, 13, 13]          16,640\n",
      "             ReLU-58          [-1, 256, 13, 13]               0\n",
      "           Conv2d-59          [-1, 256, 13, 13]         147,712\n",
      "             ReLU-60          [-1, 256, 13, 13]               0\n",
      "             Fire-61          [-1, 512, 13, 13]               0\n",
      "          Dropout-62          [-1, 512, 13, 13]               0\n",
      "           Conv2d-63            [-1, 5, 13, 13]           2,565\n",
      "             ReLU-64            [-1, 5, 13, 13]               0\n",
      "AdaptiveAvgPool2d-65              [-1, 5, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 725,061\n",
      "Trainable params: 725,061\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 51.19\n",
      "Params size (MB): 2.77\n",
      "Estimated Total Size (MB): 54.53\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import squeezenet1_1, SqueezeNet1_1_Weights\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "# DEVICE SETUP\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# BUILD MODEL\n",
    "weights = SqueezeNet1_1_Weights.IMAGENET1K_V1  # Load the predefined weights\n",
    "global_model = squeezenet1_1(weights=weights)  # Initialize the model with weights\n",
    "global_model.classifier[1] = nn.Conv2d(512, 5, kernel_size=(1,1), stride=(1,1))  # Modify the classifier for 5 classes\n",
    "global_model.num_classes = 5\n",
    "global_model.to(device)  # Move the model to the appropriate device\n",
    "summary(global_model, input_size=(3, 224, 224), device=device.type)  # Display the model summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b0ce082-25ee-4c1b-ac2a-c911b592a25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Local Models and Optimizers #############\n",
    "local_models = []\n",
    "local_optimizers = []\n",
    "\n",
    "for u in range(args.num_users):\n",
    "    local_models.append(copy.deepcopy(global_model))\n",
    "\n",
    "    if args.optimizer == 'sgd':\n",
    "        optimizer = torch.optim.SGD(local_models[u].parameters(), lr=args.lr, \n",
    "                                    momentum=args.momentum)        \n",
    "    elif args.optimizer == 'adam':\n",
    "        optimizer = torch.optim.Adam(local_models[u].parameters(), lr=args.lr)             \n",
    "\n",
    "    local_optimizers.append(optimizer)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbe49dcd-5d29-47a2-84d5-aa48419cbb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "Average train loss: 1.0003109065497793\n",
      "Test Accuracy: 69.49%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.843992548744853\n",
      "Test Accuracy: 70.59%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.821126664557108\n",
      "Test Accuracy: 71.41%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.7633397099448413\n",
      "Test Accuracy: 74.15%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.7642541382370925\n",
      "Test Accuracy: 74.28%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.7103898452549446\n",
      "Test Accuracy: 72.91%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.6878132020554891\n",
      "Test Accuracy: 74.42%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.6973631723624903\n",
      "Test Accuracy: 73.87%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.659292724074387\n",
      "Test Accuracy: 70.31%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.6763743627362135\n",
      "Test Accuracy: 72.64%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.6444305879313771\n",
      "Test Accuracy: 76.06%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.6077793124245434\n",
      "Test Accuracy: 70.59%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.6533632249366946\n",
      "Test Accuracy: 71.14%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.6114840427549874\n",
      "Test Accuracy: 76.61%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.6413475442223433\n",
      "Test Accuracy: 73.46%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.5968182057869144\n",
      "Test Accuracy: 75.92%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.5995701158918986\n",
      "Test Accuracy: 76.33%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.5533495261901762\n",
      "Test Accuracy: 76.74%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.558548473003434\n",
      "Test Accuracy: 76.61%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.5283180373470958\n",
      "Test Accuracy: 77.56%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.5315917265124437\n",
      "Test Accuracy: 76.88%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.5218590737842932\n",
      "Test Accuracy: 76.47%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.5339818902131988\n",
      "Test Accuracy: 74.42%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.5383645921218686\n",
      "Test Accuracy: 76.61%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.48841214034615493\n",
      "Test Accuracy: 77.29%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.4905084266168315\n",
      "Test Accuracy: 73.05%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.47766987361559055\n",
      "Test Accuracy: 78.52%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.483272654254262\n",
      "Test Accuracy: 76.47%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.44563454971080874\n",
      "Test Accuracy: 77.43%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.47690828144550323\n",
      "Test Accuracy: 76.61%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.44662293210262205\n",
      "Test Accuracy: 78.25%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.43923841089737126\n",
      "Test Accuracy: 76.88%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.41208328997216576\n",
      "Test Accuracy: 77.29%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.4020702181065955\n",
      "Test Accuracy: 76.61%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.3927426628950166\n",
      "Test Accuracy: 76.33%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.4165795910649183\n",
      "Test Accuracy: 77.56%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.38858377533714944\n",
      "Test Accuracy: 77.29%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.3692609180764454\n",
      "Test Accuracy: 76.88%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.38005683989059635\n",
      "Test Accuracy: 77.15%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.3829011760833787\n",
      "Test Accuracy: 77.43%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.4111966083689434\n",
      "Test Accuracy: 78.52%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.3829106161507165\n",
      "Test Accuracy: 71.41%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.39387788060234813\n",
      "Test Accuracy: 76.33%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.3458427506976011\n",
      "Test Accuracy: 78.66%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.35825603001001405\n",
      "Test Accuracy: 76.33%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.38131479192070844\n",
      "Test Accuracy: 77.29%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.31884601821259756\n",
      "Test Accuracy: 78.11%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.3039908296451336\n",
      "Test Accuracy: 76.20%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.28616566210985184\n",
      "Test Accuracy: 77.43%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.28665416015357503\n",
      "Test Accuracy: 77.56%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.30426292666574806\n",
      "Test Accuracy: 75.79%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.3010733705468294\n",
      "Test Accuracy: 77.70%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.31209896504879\n",
      "Test Accuracy: 76.88%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.27334908159767707\n",
      "Test Accuracy: 77.56%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.2708659457360826\n",
      "Test Accuracy: 77.29%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.2780046550239005\n",
      "Test Accuracy: 75.92%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.2925234160772184\n",
      "Test Accuracy: 76.47%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.2592014962943589\n",
      "Test Accuracy: 77.70%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.24194568831746172\n",
      "Test Accuracy: 77.43%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.30091159736237877\n",
      "Test Accuracy: 76.47%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.2562591377191427\n",
      "Test Accuracy: 75.79%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.23278319744802103\n",
      "Test Accuracy: 75.10%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.19498509968199382\n",
      "Test Accuracy: 73.05%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.2292225898765936\n",
      "Test Accuracy: 74.69%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.20636306139754085\n",
      "Test Accuracy: 77.43%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.18274050841971143\n",
      "Test Accuracy: 73.60%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.23510889854373002\n",
      "Test Accuracy: 76.61%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.1745212696856115\n",
      "Test Accuracy: 72.91%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.21395864573920645\n",
      "Test Accuracy: 74.83%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.1813527401991007\n",
      "Test Accuracy: 76.20%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.18968629500851397\n",
      "Test Accuracy: 73.73%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.2035423599001838\n",
      "Test Accuracy: 75.38%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.16615818559033116\n",
      "Test Accuracy: 75.24%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.16024609591539313\n",
      "Test Accuracy: 75.79%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.1466213048594754\n",
      "Test Accuracy: 74.83%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.225624399941142\n",
      "Test Accuracy: 74.28%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.22054410580454803\n",
      "Test Accuracy: 77.02%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.1284321477500404\n",
      "Test Accuracy: 75.92%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.10385864228010178\n",
      "Test Accuracy: 76.06%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.1344766463720944\n",
      "Test Accuracy: 72.91%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.23200885769797536\n",
      "Test Accuracy: 74.97%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.17295370941481938\n",
      "Test Accuracy: 73.87%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.11687476187944412\n",
      "Test Accuracy: 77.02%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.11749985159897222\n",
      "Test Accuracy: 77.02%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.12027716759319712\n",
      "Test Accuracy: 75.24%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.13412557097106445\n",
      "Test Accuracy: 77.84%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.10152445947069948\n",
      "Test Accuracy: 77.02%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.07927295685995643\n",
      "Test Accuracy: 75.79%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.0920849700980797\n",
      "Test Accuracy: 74.42%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.09586924432617862\n",
      "Test Accuracy: 72.37%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.12750120978893303\n",
      "Test Accuracy: 75.92%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.08844840217654298\n",
      "Test Accuracy: 76.88%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.08472067681027622\n",
      "Test Accuracy: 76.47%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.08892561218178854\n",
      "Test Accuracy: 75.92%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.09419739478063292\n",
      "Test Accuracy: 76.20%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.06424937283665669\n",
      "Test Accuracy: 75.79%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.05311518178389567\n",
      "Test Accuracy: 75.51%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.06735571201254682\n",
      "Test Accuracy: 76.74%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.0873224933109269\n",
      "Test Accuracy: 78.80%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n",
      "\n",
      "Epoch: 1\n",
      "Average train loss: 0.08432920963117262\n",
      "Test Accuracy: 74.83%\n",
      "Results saved to /home/mahsa/Desktop/FL/src/Inversion_Attack_Results/non_private_ML.pth\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "train_loss = []\n",
    "test_log = []\n",
    "epsilon_log = []\n",
    "\n",
    "for epoch in range(args.epochs):         \n",
    "    idxs_users = np.random.choice(range(args.num_users),\n",
    "                                  max(int(args.frac * args.num_users), 1),\n",
    "                                  replace=False)\n",
    "\n",
    "    local_weights, local_losses = [], []    \n",
    "    all_output_gradients = []\n",
    "    \n",
    "    for u in idxs_users:\n",
    "        local_model = LocalUpdate(args=args, dataset=train_dataset, \n",
    "                                  u_id=u, idxs=user_groups[u],\n",
    "                                  optimizer = local_optimizers[u])\n",
    "        w, loss, local_optimizers[u], user_output_gradients = local_model.update_weights(\n",
    "                                                model=local_models[u],\n",
    "                                                global_round=epoch,\n",
    "                                                test_dataset=test_dataset)\n",
    "        local_weights.append(copy.deepcopy(w))\n",
    "        local_losses.append(copy.deepcopy(loss))\n",
    "        all_output_gradients.extend(user_output_gradients)  # Collect output gradients from each user\n",
    "        \n",
    "    # update global weights\n",
    "    global_weights = average_weights(local_weights)\n",
    "\n",
    "    # update global weights\n",
    "    global_model.load_state_dict(global_weights)\n",
    "    for u in range(args.num_users):\n",
    "        local_models[u].load_state_dict(global_weights)\n",
    "\n",
    "    loss_avg = sum(local_losses) / len(local_losses)        \n",
    "    train_loss.append(loss_avg)\n",
    "\n",
    "    _acc, _loss = test_inference(args, global_model, test_dataset)        \n",
    "    test_log.append([_acc, _loss])  \n",
    "\n",
    "    if args.withDP:                        \n",
    "        epsilon_log.append(list(epsilons))\n",
    "    else:\n",
    "        epsilon_log = None\n",
    "    \n",
    "    save_results(global_model, train_loss, test_log, all_output_gradients)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
